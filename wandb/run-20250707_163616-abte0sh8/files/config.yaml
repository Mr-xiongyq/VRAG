_wandb:
    value:
        cli_version: 0.20.1
        m: []
        python_version: 3.10.18
        t:
            "1":
                - 1
                - 5
                - 11
                - 30
                - 41
                - 49
                - 53
                - 71
                - 95
                - 105
            "2":
                - 1
                - 5
                - 11
                - 30
                - 41
                - 49
                - 53
                - 71
                - 95
                - 105
            "3":
                - 2
                - 13
                - 16
                - 55
            "4": 3.10.18
            "5": 0.20.1
            "6": 4.51.3
            "12": 0.20.1
            "13": linux-x86_64
actor_rollout_ref:
    value:
        actor:
            clip_ratio: 0.2
            entropy_coeff: 0
            fsdp_config:
                fsdp_size: -1
                optimizer_offload: true
                param_offload: true
                wrap_policy:
                    min_num_params: 0
            grad_clip: 1
            kl_loss_coef: 0.01
            kl_loss_type: low_var_kl
            optim:
                lr: 1e-06
                lr_warmup_steps: 5
                lr_warmup_steps_ratio: 0.285
                min_lr_ratio: null
                total_training_steps: 1769
                warmup_style: constant
            ppo_epochs: 1
            ppo_max_token_len_per_gpu: 16384
            ppo_micro_batch_size: null
            ppo_micro_batch_size_per_gpu: 1
            ppo_mini_batch_size: 6
            shuffle: false
            state_masking: true
            strategy: fsdp
            ulysses_sequence_parallel_size: 1
            use_dynamic_bsz: false
            use_kl_loss: true
            use_torch_compile: true
        hybrid_engine: true
        model:
            enable_gradient_checkpointing: true
            external_lib: null
            path: Qwen/Qwen2.5-VL-3B-Instruct
            use_remove_padding: true
        ref:
            fsdp_config:
                param_offload: true
                wrap_policy:
                    min_num_params: 0
            log_prob_max_token_len_per_gpu: 16384
            log_prob_micro_batch_size: null
            log_prob_micro_batch_size_per_gpu: 1
            log_prob_use_dynamic_bsz: false
            ulysses_sequence_parallel_size: 1
        rollout:
            disable_log_stats: false
            do_sample: true
            dtype: bfloat16
            enable_chunked_prefill: false
            enforce_eager: false
            free_cache_engine: false
            gpu_memory_utilization: 0.6
            ignore_eos: false
            load_format: dummy_dtensor
            log_prob_max_token_len_per_gpu: 16384
            log_prob_micro_batch_size: null
            log_prob_micro_batch_size_per_gpu: 1
            log_prob_use_dynamic_bsz: false
            max_model_len: null
            max_num_batched_tokens: 16384
            max_num_seqs: 1024
            "n": 1
            n_agent: 1
            name: vllm
            prompt_length: 8192
            response_length: 2048
            temperature: 1
            tensor_model_parallel_size: 1
            top_k: -1
            top_p: 1
            use_fire_sampling: false
            val_kwargs:
                do_sample: false
                "n": 1
                temperature: 0
                top_k: -1
                top_p: 1
algorithm:
    value:
        adv_estimator: grpo
        filter_groups:
            enable: false
        gamma: 1
        kl_ctrl:
            kl_coef: 0
            type: fixed
        kl_penalty: kl
        lam: 1
        state_masking:
            end_state_marker: |
                <|im_end|>
                <|im_start|>assistant
            start_state_marker: |4
                <|im_start|>user
critic:
    value:
        cliprange_value: 0.5
        forward_max_token_len_per_gpu: 32768
        forward_micro_batch_size: null
        forward_micro_batch_size_per_gpu: null
        grad_clip: 1
        model:
            enable_gradient_checkpointing: true
            external_lib: null
            fsdp_config:
                fsdp_size: -1
                optimizer_offload: false
                param_offload: false
                wrap_policy:
                    min_num_params: 0
            path: ~/models/deepseek-llm-7b-chat
            tokenizer_path: Qwen/Qwen2.5-VL-3B-Instruct
            use_remove_padding: false
        optim:
            lr: 1e-05
            lr_warmup_steps_ratio: 0
            min_lr_ratio: null
            total_training_steps: 1769
            warmup_style: constant
        ppo_epochs: 1
        ppo_max_token_len_per_gpu: 32768
        ppo_micro_batch_size: null
        ppo_micro_batch_size_per_gpu: null
        ppo_mini_batch_size: 6
        shuffle: false
        strategy: fsdp
        ulysses_sequence_parallel_size: 1
        use_dynamic_bsz: false
custom_reward_function:
    value:
        name: compute_score
        path: null
data:
    value:
        filter_overlong_prompts: false
        image_key: images
        max_prompt_length: 8192
        max_response_length: 2048
        prompt_key: prompt
        return_raw_chat: false
        return_raw_input_ids: false
        shuffle: true
        tokenizer: null
        train_batch_size: 6
        train_files: /data3/xiongyuqi/data/rag/slidevqa_train_crop_3.parquet
        truncation: error
        val_batch_size: null
        val_files: /data3/xiongyuqi/data/rag/overall_test_crop_3.parquet
do_search:
    value: true
max_turns:
    value: 4
retriever:
    value:
        url: http://0.0.0.0:8002/search
reward_model:
    value:
        enable: false
        forward_max_token_len_per_gpu: 32768
        max_length: null
        micro_batch_size: null
        micro_batch_size_per_gpu: null
        model:
            external_lib: null
            fsdp_config:
                fsdp_size: -1
                param_offload: false
                wrap_policy:
                    min_num_params: 0
            input_tokenizer: Qwen/Qwen2.5-VL-3B-Instruct
            path: ~/models/FsfairX-LLaMA3-RM-v0.1
            use_remove_padding: false
        reward_manager: rm
        rm_url: http://0.0.0.0:8003/eval
        strategy: fsdp
        ulysses_sequence_parallel_size: 1
        use_dynamic_bsz: false
trainer:
    value:
        balance_batch: true
        critic_warmup: 0
        default_hdfs_dir: null
        default_local_dir: checkpoints/vrag/SFT_w_crop_2_gpus_4_maxturns_1_ngroups_qwen2_5_vl_7b
        del_local_ckpt_after_load: false
        experiment_name: SFT_w_crop_2_gpus_4_maxturns_1_ngroups_qwen2_5_vl_7b
        logger:
            - console
            - wandb
        n_gpus_per_node: 2
        nnodes: 1
        project_name: vrag
        remove_previous_ckpt_in_save: false
        resume_from_path: false
        resume_mode: disable
        save_freq: 50
        test_freq: 50
        total_epochs: 1
        total_training_steps: null
        val_before_train: false
        val_generations_to_log_to_wandb: 0
